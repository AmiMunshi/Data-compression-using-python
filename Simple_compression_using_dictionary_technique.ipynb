{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of encoded string is:119 bytes\n",
      "{'and': 4, 'or': 2, 'with': 2, 'not': 2, 'go': 2, 'for': 3, 'got': 1, 'on': 1, 'there': 1}\n",
      "\n",
      "Dataframe of word and its corresponding frequency is:\n",
      "\n",
      "    word  frequency\n",
      "0    and          4\n",
      "1     or          2\n",
      "2   with          2\n",
      "3    not          2\n",
      "4     go          2\n",
      "5    for          3\n",
      "6    got          1\n",
      "7     on          1\n",
      "8  there          1\n",
      "\n",
      " The dictionary with word and its corresponding index is:\n",
      "\n",
      "{'and': 1, 'or': 2, 'with': 3, 'not': 4, 'go': 5, 'for': 6, 'got': 7, 'on': 8, 'there': 9}\n",
      "\n",
      " The encoded string is:\n",
      "\n",
      "[1, 2, 1, 3, 2, 4, 5, 6, 1, 4, 7, 6, 3, 1, 6, 5, 8, 9]\n",
      "The size of encoded string is:103 bytes\n"
     ]
    }
   ],
   "source": [
   
    "string1= \"and or and with or not go for and not got for with and for go on there\" ## Enter the string to be compressed\n",
    "print('The size of encoded string is:'+str(sys.getsizeof(string1)) +' bytes')\n",
    "list1= string1.split() #separate individual words in the string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "dict1={} ## create dictionary to store the word in the list as key and iths freuquency as value\n",
    "\n",
    "for i in list1:\n",
    "    count= list1.count(i) #count frequency of occurence of word in the list\n",
    "    temp= {i:count} \n",
    "    dict1.update(temp) # update the dictionary with word and its frequency\n",
    "\n",
    "a= np.array(dict1)\n",
    "print(a)\n",
    "\n",
    "import pandas as pd\n",
    "df1=pd.DataFrame(dict1.items()) #display the dictionary as dataframe using pandas\n",
    "df1.columns= ['word', 'frequency']\n",
    "#Display the dataframe with word and its frequency\n",
    "print(\"\\nDataframe of word and its corresponding frequency is:\\n\")\n",
    "print(df1)\n",
    "\n",
    "k=0\n",
    "dict2={} # create one more dictionary to store word and its corresponding index\n",
    "for key1 in dict1:\n",
    "    k= k+1\n",
    "    temp = {key1:k}\n",
    "    dict2.update(temp)\n",
    "print(\"\\n The dictionary with word and its corresponding index is:\\n\")\n",
    "print(dict2)\n",
    "list2=[]\n",
    "##output the index of the word in the list to obtain compressed text\n",
    "for p in range(len(list1)):\n",
    "    for j in dict2:\n",
    "        if j== list1[p]:\n",
    "            list2.append(dict2[j])\n",
    "string2 =str(list2)\n",
    "\n",
    "print(\"\\n The encoded string is:\\n\")\n",
    "print(string2)\n",
    "print('The size of encoded string is:'+str(sys.getsizeof(string2)) +' bytes')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
